# Example Dockerfile for running HuggingFace + PyTorch CPU model inside container
# Note: This image will be larger. Use only if you need to run your HF model in-container.

FROM pytorch/pytorch:2.2.0-cpu-py3.11

WORKDIR /app

# Copy app
COPY api/ ./api
COPY ticket_classifier_deployment/ ./ticket_classifier_deployment
COPY frontend/ ./frontend

# Install Python deps
RUN pip install --upgrade pip
RUN pip install fastapi uvicorn[standard] transformers==4.30.2

EXPOSE 8000

CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8000"]
